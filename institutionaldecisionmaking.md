---
layout: page
title: Improving Institutional Decision Making
permalink: /institutionaldecisionmaking
---

# The problem

Human brains evolved to be terrible at forming accurate beliefs about politics and big societal issues. We're all extremely biased and self-deluded. The most respected form of societal decision making (voting) involves a simple aggregation of our highly flawed beliefs. This negatively and significantly impacts almost every aspect of our lives.

Similar to how solving AI is a meta-solution because a good enough AI could solve all our other problems, solving political decision making could significantly improve our solutions to all large scale object level problems.

# The extent of our biases and delusion is vastly underestimated

Much of what motivates humans is [signaling and tribal politics](http://elephantinthebrain.com/). We are self deceived about our motivations and lack the ability to introspect to discover what is actually motivating us (see [the work of Robert Kurzban](http://rationallyspeakingpodcast.org/show/rs-188-robert-kurzban-on-being-strategically-wrong.html) on the modularity of the brain). It is likely that our reasoning ability evolved in large part to [help us win arguments](http://lesswrong.com/lw/1wu/reasoning_isnt_about_logic_its_about_arguing/) to benefit ourselves or our factions in disputes within our tribe. People are especially prone to truth-blind beliefs when in ["far" mental mode](http://www.overcomingbias.com/2010/06/near-far-summary.html ), which is usually the mode we use to discuss politics.

Our self-deception is so strong that it's nearly impossible to internalize and react appropriately to it. People who intellectually understand all of the above still behave as if they are the exception.

# Idea pollution

Everyone's flawed beliefs are being used as inputs to a process that generates all of our societal decisions. These beliefs have externalities that are analogous to pollution. 

One way to improve societal decision making would be to somehow significantly reduce/punish this pollution, and to encourage beliefs that instead had positive externalities.

# Failed solutions

One popular class of failed solutions involves educating people. These solutions underestimate how deep rooted our biases are. Knowledge doesn't protect against bias. If your brain doesn't want to seek truth, then no matter how much you learn about biases or policy you'll come up with ways to tell yourself that you're accounting for the relevant biases and weighing all factors appropriately and therefore your conclusions are rational and the result of a truth-seeking process.

Another failed solution involves essentially ignoring the problem / pretending people are truth-seeking enough in political contexts that our current institutions are fine. One might (rightly) claim that we don't need individuals to be truth-seeking as long as we have a good mechanism to somehow transform people's beliefs/actions into good societal decisions. Unfortunately voting by itself is not such a mechanism. See [Bryan Caplan](https://en.wikipedia.org/wiki/The_Myth_of_the_Rational_Voter#Rational_irrationality) and [Patri Friedman's](https://www.youtube.com/watch?v=rKoh4kKl08A) critiques of democracy.

# General approaches to a better solution

I see two general angles of approach: 

(1) Making it harder / less appealing for people to hold false political beliefs and easier / more attractive to hold true ones. This wouldn't require a change in our political institutions, but would probably require a big change in social institutions or norms.

(2) Changing our political institutions to make decisions differently.

# Promising mechanisms

There is a lot of evidence (and theoretical support) suggesting that prediction markets are excellent truth-seeking mechanisms in many contexts. They are extremely hard to manipulate, as people can profit by counteracting any manipulation attempts.

The [Good Judgment Project](https://www.gjopen.com/ ) has also had success creating truth-seeking mechanisms other than prediction markets (but which still rely on making concrete predictions and being rewarded based on their accuracy). 

In general, making concrete predictions with incentives for good results and disincentives for bad results seems to significantly increase truth-seeking. As mentioned previously, people in [http://www.overcomingbias.com/2010/06/near-far-summary.html "far" mental mode] more often form truth-blind beliefs. There is evidence that making concrete predictions puts people in 'near' mode.

# Concrete project ideas

So predictions markets, betting on beliefs, and using the judgment of superforecasters are all great. What specifically should we do to move society in a direction where more of our important decisions are based on those mechanisms? Or how can we figure out which other mechanisms might help us make better decisions?

### Research

This is a hard problem and I'm not sure yet of the best path to get us from where we are now to a situation where society actually uses these better mechanisms for important decisions. So probably a lot of what is needed initially is for smart people to think about what approaches might be worth exploring.

### Funding specific prediction markets

With the recent release of [Augur](https://www.augur.net/), there now exists a prediction market platform that anyone can use to bet any amount of money on an outcome. The UX is currently terrible and thus usage is pretty low. However well publicized funding of some specific interesting markets (via noise trades) may make it worthwhile for experts to deal with the bad UX in exchange for free money. For instance, those concerned about AI risk might fund a market about whether a given AI milestone will be reached before a certain date.

Augur can also be used to fund decision markets, for instance estimating GDP or crime metrics depending on whether a given law gets passed or president gets elected. 

One idea is to create a charity that takes donations regarding a certain question and figures out the logistics of how to best fund prediction markets to get the best answer to that question.

### Technical work on prediction markets or betting platforms

There are currently big UX problems with Augur. One option is to fund developers to make decentralized prediction markets more usable.

Alternatively, an Augur-like platform for peer to peer betting could be developed to encourage a culture of betting on beliefs. Such a platform could plausibly become popular on Twitter (initially among the GMU economics and rationalist/EA crowds and ideally spreading out from there), providing an example to the world of how betting can serve a social good.

Update: [veil](https://veil.co/) and [guesser](https://www.guesser.io/) are two recently launched attempts to add a centralized UI layer on top of Augur. So this aspect of the problem seems like it's being worked on by for-profit companies.

### Lobbying for exceptions to betting/gambling laws

The main reason why the Augur UX is so terrible is that it had to be built in a decentralized way to get around legal issues with building a prediction market. Most laws against betting and gambling were not written with the knowledge that betting could be done in a way to have socially desirable outcomes. Possibly there are some jurisdictions that would be receptive to making some "betting for good" exceptions in their laws.

### Finding ways to spin up small-scale trials of these ideas

If I'm right in my thesis, implementing these ideas will lead to better group decisions. If we have lots of small scale successes, it will become progressively easier to make the case that these mechanisms should be used for other decisions.

For instance, Robin Hanson has [a cool proposal](https://www.overcomingbias.com/2018/11/how-to-fund-prestige-science.html ) to use prediction markets to fund scientific research by betting on the future prestige of papers/people/projects/institutions. 

### Marketing the positive properties of betting on beliefs / prediction markets / forecasting tournaments

To get from where we are now to a world where prediction markets / betting / forecasting tournaments are widely used and respected, a lot of people's beliefs about these things will have to change. Possibly a lot of this can be done by starting small and accumulating a good track record with these mechanisms. However the amount of opportunities that we get to try these mechanisms will likely be a limiting factor, and good marketing can increase these opportunities. 

For instance I've found that people are very receptive to the message that lots of people engaged in political debate are far too confident, and that encouraging betting on beliefs helps punish these people. When people hear this they imagine how overconfident their opponents are and imagine them being punished, and think it's a cool idea. 

Most people also seem genuinely ignorant of the effectiveness of prediction markets (their first response to the suggestion of prediction markets is often "then the rich will control everything!"), so marketing to counter that misconception may be helpful.

### Making the culture of making concrete predictions "cool", and refusing to do so "uncool"

A societal norm in which people who made confident predictions were expected to bet on them (or were ignored) would reduce a lot of our idea-pollution.

Prediction markets are already slowly being taken more seriously. Betting odds are now regularly discussed in relation to US presidential elections. It's unclear how to accelerate this process. 

One possibility is the creation of a platform to track predictions made externally by public figures / bloggers. One platform that currently does something like this is [longbets](http://longbets.org/).

The end goal would be a culture where people who refuse to bet on their beliefs (or at least make concrete predictions) are either shamed or ignored, and betting or giving concrete predictions which are tracked becomes necessary for being taken seriously in more intellectual spheres. This is already kind of a thing among GMU economists and rationalists. [Scott Alexander](https://slatestarcodex.com/) is playing a small part in normalizing making concrete predictions as he becomes more popular.

### Experiment with futarchy on a public blockchain

[Futarchy](https://en.wikipedia.org/wiki/Futarchy) is a political system that directly uses prediction markets to make decisions. We're a long way from having it adopted in any country (hopefully some other ideas on this page will get us closer to that goal), but cryptocurrencies give us new jurisdictions to experiment with which are hard for existing authorities to regulate.

### Other stuff??

I'm very interested in more ideas that may have a high ROI for replacing our current decision making mechanisms with better ones. Let me know if you have ideas. My first and last name at gmail.

# Some obstacles

Prediction markets and merit-based forecasting mechanisms reduce the power of existing decision makers, who often use their power to benefit themselves at the expense of the whole. So there will be a lot of resistance from these people to this project.

Betting also has a reputation as something that lowlifes are into, and as being a societal problem that must be minimized. It will probably be pretty hard to get people to start thinking of certain types of betting as socially beneficial.

[Kyle Samani points out](https://twitter.com/KyleSamani/status/1114944770676277249 ) that betting feels confrontational and uncomfortable to many people. If you're having a discussion and ask someone to bet with you, you have to work hard to make it not come off as a social attack.
